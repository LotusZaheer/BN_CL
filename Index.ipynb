{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Index.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"cells":[{"cell_type":"code","metadata":{"id":"Byt_fKVmpcwY","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pyWLmueXasd5","colab_type":"text"},"source":["<img src=\"https://raw.githubusercontent.com/LotusZaheer/BN_CL/master/Banner.jpg\" align=\"center\"/>"]},{"cell_type":"markdown","metadata":{"id":"QW4HoP_1q9dH","colab_type":"text"},"source":["<h4>Universidad Industrial de Santander</h4>\n","<h3>Inteligencia Artificial I - J1</h3>\n","<h3>Profesor Gustavo Adolfo Garzón Villamizar</h3>\n","<br>\n","Andrés Felipe Uribe García - 2160793\n","<br>\n","Julian Orlando Rodríguez Villamizar - 2170137"]},{"cell_type":"markdown","metadata":{"id":"rCVv3-A3LAD4","colab_type":"text"},"source":["Los datos provienen del dataset https://www.kaggle.com/chetankv/dogs-cats-images el cual fue utilizado para un problema de clasificación binaria de perros y gatos"]},{"cell_type":"markdown","metadata":{"id":"W6xpYQbILBw_","colab_type":"text"},"source":["\n","Para el preprocesado del dataset de gatos se utilizó un for en bash con la instrución \n","<br>\n","convert i.jpg -colorspace Gray i.jpg\n","<br>\n","La cual transforma todas las imagenes de color a escala de grises utilizando la aplicación ImageMagick, la cual tambien ofrece otro tipo de transformaciones\n","<br>\n","Tutorial rapido: https://blog.desdelinux.net/como-manipular-imagenes-desde-el-terminal/\n","Proyecto: https://github.com/ImageMagick/ImageMagick\n"]},{"cell_type":"code","metadata":{"id":"HyJyw241e_tR","colab_type":"code","colab":{}},"source":["import os\n","import imageio\n","import numpy as np\n","from glob import glob\n","import tensorflow as tf\n","from random import randint\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","from IPython.display import Image #Error de plt\n","from tensorflow.keras.layers import *\n","from urllib.request import urlretrieve\n","from IPython.display import clear_output\n","from keras.models import Sequential, Model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5oFcR1IZxpHj","colab_type":"code","colab":{}},"source":["IMG_SIZE = 128 #A 256 demora una eternidad\n","\n","#Ruta Raiz\n","PATH = \"/content/drive/My Drive/BN_CL/\"\n","\n","#Datos de entrada a Blanco y negro\n","INPATH = PATH + \"train/\"#https://drive.google.com/drive/folders/1NkVi1_hya6J7DRfH6zq6xi_7iUraAL_N?usp=sharing\n","\n","#Datos de Generados a Color\n","OUTPATH = PATH + \"target/\" #https://drive.google.com/drive/folders/1IiIjvRJakrMCB4RDRyXYCq20Zew35sGy?usp=sharing\n","\n","#Datos de Esperados a Color\n","PREDPATH = PATH + \"output/\"\n","\n","#Cargamos SOLO el nombre de las imagenes en un listado\n","imgurls = !ls -1 \"{INPATH}\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r6q4llArc9Ni","colab_type":"code","colab":{}},"source":["n=1000\n","#Tamaño del test del 80%\n","train_n = round(n*0.8)\n","\n","#Listado randomizado\n","randurls = np.copy(imgurls)\n","\n","np.random.seed(23)\n","np.random.shuffle(randurls)\n","\n","#Partición de test y train\n","tr_urls = randurls[:train_n]\n","ts_urls = randurls[train_n:]\n","\n","print( \"Tamaño del dataset :\", len(imgurls))\n","print( \"Tamaño de los datos de entrenamiento :\", len(tr_urls))\n","print( \"Tamaño de los datos de testeo :\", len(ts_urls))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OTC4iPkIpgT_","colab_type":"code","colab":{}},"source":["#Para reducir el costo computacional\n","@tf.function\n","def rescalado(inimg, tgimg, height, width):\n","  inimg = tf.image.resize(inimg, [height, width])\n","  tgimg = tf.image.resize(tgimg, [height, width])\n","\n","  return inimg, tgimg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_nskCcLpUQvR","colab_type":"code","colab":{}},"source":["#En lugar de trabajar con valores de 0 a 255\n","#usamos datos entre -1 y 1\n","def normalizado(inimg, tgimg):\n","  #Tanh trabaja de -1 a 1 por lo cual para aprovechar su dominio no trabajaremos de 0 a 1 \n","  #si no de -1 a 1\n","  #Ver en capa resultado ↓↓↓↓↓↓↓↓\n","  inimg = (inimg /127.5) -1\n","  tgimg = (tgimg /127.5) -1\n","  return inimg, tgimg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Py33nCU3RVa7","colab_type":"code","colab":{}},"source":["#Cargamos las imagenes\n","#Nombre del archivo \n","@tf.function\n","def load_image(nombre):\n","\n","  #No lo comprendo en su totalidad :U\n","  #####Buscar documentacion#####\n","  inimg = tf.cast(tf.image.decode_jpeg(tf.io.read_file(INPATH + nombre)), tf.float32)[..., :3]\n","  tgimg = tf.cast(tf.image.decode_jpeg(tf.io.read_file(OUTPATH + nombre)), tf.float32)[..., :3]\n","  \n","  #Cargamos las imagenes e inmediatamente las rescalamos\n","  #El mismo tamaño para altura y ancho\n","  inimg, tgimg = rescalado(inimg, tgimg, IMG_SIZE, IMG_SIZE)\n","\n","  #Normalizamos\n","  inimg, tgimg = normalizado(inimg, tgimg) \n","\n","  return inimg, tgimg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NcRZQcelWI7d","colab_type":"code","colab":{}},"source":["#Probamos la función load_image\n","#Visualizamos las imagenes para ver el material a trabajar\n","#randurls[imagen])[BW=0;Color=1])\n","#Una imagen aletoria cada vez\n","rimg = randint(0,n)\n","plt.figure(figsize=(16,6))\n","plt.subplot(1,2,1)\n","plt.imshow( ((load_image(randurls[rimg])[0])+1)/2 )\n","plt.subplot(1,2,2)\n","plt.imshow( ((load_image(randurls[rimg])[1])+1)/2 )\n","plt.show()\n","#En numeriños :u\n","#(load_image(randurls[rimg])[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ufZdmYDRSSS","colab_type":"code","colab":{}},"source":["# :v/ Al fin el dataset como tal \\v:\n","\n","#Cargamos el listado de direcciones\n","X_train = tf.data.Dataset.from_tensor_slices(tr_urls)\n","X_test = tf.data.Dataset.from_tensor_slices(ts_urls)\n","\n","#Cargamos las imagenes con nuestra funcion\n","#¡IMPORTANTE! Revisar el numero de hilos o verás el azul dominar tu pantalla :u\n","X_train = X_train.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) #Mejor dejarlo en automatico\n","X_test = X_test.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","\n","#Distribuimos los datos por lotes\n","X_train = X_train.batch(1)\n","X_test = X_test.batch(1)\n","\n","\n","#Probamos que las imagenes se hayan cargado en el dataset\n","#Visualizamos las imagenes\n","for inimg, tgimg in X_test.take(2):\n","  plt.figure(figsize=(16,6))\n","  plt.subplot(1,2,1)\n","  plt.imshow(((inimg[0,...])+1)/2) #En caso de ignorar los lotes -> (((tgimg)+1)/2)\n","  plt.subplot(1,2,2)\n","  plt.imshow(((tgimg[0,...])+1)/2)\n","  plt.show()\n","#rof"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5HLcv9hXkvs","colab_type":"code","colab":{}},"source":["#Downsampling\n","def Compresion(filtros, batch_norm=True):\n","  \n","  #Capas, como una cebolla\n","  C = Sequential()\n","  #Ruido Gausiano de media 0 y desviación estandar de 0.02 \n","  initializer = tf.random_normal_initializer(0, 0.02)\n","\n","  #Capa convolucional\n","  C.add(Conv2D(filtros,\n","               kernel_size=4,\n","               strides=2, #Vamos reduciendo el tamaño de imagen a la mitad\n","               padding=\"same\",\n","               kernel_initializer=initializer,\n","               use_bias=not batch_norm))\n","  \n","  #Capa de Batch\n","  if batch_norm:\n","    C.add(BatchNormalization())\n","  #Capa de activación\n","  C.add(ReLU())\n","  return C"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L9zVd7L_fwzY","colab_type":"code","colab":{}},"source":["#Upsampling\n","def Expansion(filtros, dropout=True):\n","  \n","  #Capas, como una cebolla\n","  E = Sequential()\n","  #Ruido Aleatorio\n","  initializer = tf.random_normal_initializer(0, 0.02)\n","\n","  #Capa convolucional\n","  E.add(Conv2DTranspose(filtros,\n","                        kernel_size=4,\n","                        strides=2, #Vamos reduciendo el tamaño de imagen a la mitad\n","                        padding=\"same\",\n","                        kernel_initializer=initializer,\n","                        use_bias=False))\n","\n","  #Capa de Batch para trabajar por lotes\n","  if dropout:\n","    E.add(Dropout(0.5))\n","\n","  #Capa de activación\n","  E.add(ReLU())\n","\n","  return E"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YDNhYMc2hRSc","colab_type":"code","colab":{}},"source":["def Generador():\n","  \n","  inputs = Input(shape=[None, None, 3]) #Img_size no especificados, 3 colores\n","\n","  Encoder = [         #Tamaño\n","      Compresion(64, batch_norm=False), #128\n","      Compresion(128),#64\n","      Compresion(256),#32\n","      Compresion(256),#16\n","      Compresion(256),#8\n","      Compresion(256),#4\n","      Compresion(256),#2\n","      ##Para trabajar con 256 descomente esta linea\n","      #Compresion(256),#1\n","  ]\n","  \n","  Decoder = [        #Tamaño\n","      ##Para trabajar con 256 descomente esta linea\n","      #Expansion(256),#2\n","      Expansion(256),#4\n","      Expansion(256),#8\n","      Expansion(256, dropout=False),#16\n","      Expansion(256, dropout=False),#32\n","      Expansion(128, dropout=False),#64\n","      Expansion(64, dropout=False), #128\n","  ]\n","\n","\n","  I = tf.random_normal_initializer(0, 0.02)\n","  \n","  #Tamaño 128\n","  Resultado = Conv2DTranspose(filters=3,\n","                              kernel_size=4,\n","                              strides=2,\n","                              padding=\"same\",\n","                              kernel_initializer=I, \n","                              activation='tanh') #Errores con la normalización\n","  \n","  x = inputs\n","  s = [] #Lista con los saltos de conexión \n","  concat = Concatenate()\n","\n","  #Pasamos el resultado de cada capa a la siguiente\n","  for i in Encoder:\n","    x = i(x)\n","    s.append(x)\n","  #rof\n","\n","  #La primera en entrar debe ser la ultima en salir\n","  #El elemento de la capa de tamaño 1 al ser el centro la eliminamos\n","  s = reversed(s[:-1]) \n","  \n","  \n","  for j, sl in zip(Decoder, s):\n","    x = j(x)\n","    x = concat([x, sl]) #Concexion de los datos que saltaron\n","  #rof\n","\n","  output = Resultado(x)\n","\n","  return Model(inputs=inputs, outputs=output) \n"," "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ItPjGptVynUV","colab_type":"code","colab":{}},"source":["#Utilizaremos un patchGAN discriminator :u\n","#En lugar de Evaluar por imagenes lo haremos por parches\n","#aprovechando que tenemos el codigo por piezas\n","\n","def Discriminador():\n","  ini = Input(shape=[None, None, 3], name=\"input_img\")\n","  gen = Input(shape=[None, None, 3], name=\"gen_img\")\n","\n","  con = concatenate([ini, gen])\n","\n","  I = tf.random_normal_initializer(0, 0.02)\n","  \n","  dec1 = Compresion(32, batch_norm=False)(con)\n","  dec2 = Compresion(64)(dec1)\n","  dec3 = Compresion(128)(dec2)\n","  dec4 = Compresion(256)(dec3)\n","  \n","  Resultado = Conv2DTranspose(filters=1,\n","                              kernel_size=4,\n","                              strides=1,\n","                              kernel_initializer=I, \n","                              padding=\"same\")(dec4)\n","  \n","  return Model(inputs=[ini, gen], outputs=Resultado)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5EsCTHzTbFek","colab_type":"code","colab":{}},"source":["#Creamos el generador\n","G = Generador()\n","#Resumen del Modelo Generador\n","G.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cuSjHSTabQVD","colab_type":"code","colab":{}},"source":["#Creamos el Discriminador\n","D = Discriminador()\n","#Resumen del Modelo Discriminador\n","D.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zNNw2uBe3wgu","colab_type":"code","colab":{}},"source":["#Test de ejemplo:\n","#Lo que genera el modelo\n","og = G(((inimg+1)*255), training=False) \n","\n","#Test de ejemplo:\n","#Lo que considera es falso\n","od = D([((inimg+1)*255), og], training=False)\n","\n","#PLoteamos para ver las diferencias\n","plt.figure(figsize=(16,6))\n","\n","plt.subplot(1,2,1)\n","plt.imshow(og[0,...])\n","\n","plt.subplot(1,2,2)\n","plt.imshow(od[0,...,-1],\n","           vmin=-5, vmax=5,\n","           cmap='RdBu_r') #'RdBu_r'\n","plt.colorbar()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wwDtWTbPwg4H","colab_type":"code","colab":{}},"source":["#Entropía cruzada de cada pixel obtenido\n","#'from_logits' con ella normalizamos para qeu exista en [0. .1]\n","loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YGs_sPjw4P6X","colab_type":"code","colab":{}},"source":["#Evaluamos el Discriminador\n","\n","#Con ella vamos a tomar los datos del generador y el discriminador \n","#para que así vayan mejorando uno a la par del otro\n","def discrimator_loss(real_output, pred_output):\n","  \n","  #Diferencia entre la imagen real y lo que el discriminador piensa es real\n","  #Con ones_like establecemos que la imagen es real, dando por buena toda su extensión \n","  real_loss = loss_object(tf.ones_like(real_output), real_output)\n","  \n","  #Diferencia entre la imagen predicha y lo que el discriminador piensa es real\n","  #Con zero_like establecemos que la imagen es predicha, dando por falsa toda su extensión \n","  pred_loss = loss_object(tf.zeros_like(pred_output), pred_output)\n","  \n","  #Sumamos las diferencias de ambas operaciones\n","  total_loss = real_loss + pred_loss\n","\n","  return total_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kyRCti7HwHKr","colab_type":"code","colab":{}},"source":["#Evaluamos el Generador\n","L = 100 \n","\n","#El mapa generado por el discriminador, Imagen generada y la imagen esperada\n","def generator_loss(output_disc, pred_output, target):\n","\n","  #Diferencia entre la imagen predicha y lo que el discriminador piensa es real\n","  #Con ones_like establecemos que la imagen es predicha es adecuada dandola por verdadera\n","  gan_loss = loss_object(tf.ones_like(output_disc), output_disc)\n","  \n","  #Error absoluto\n","  #La diferencia entre lo que generamos y lo esperabamos\n","  abs_loss = tf.reduce_mean(tf.abs(target - pred_output))\n","\n","  #Multiplicando por Lambda damos un mayor valor al error absoluto de la predicción\n","  total_loss =  gan_loss +(L * abs_loss)\n","  \n","  return total_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hpqhNfqf9K5u","colab_type":"code","colab":{}},"source":["#Optimizamos utilizando Adam con los valores\n","generador_optimizer = tf.keras.optimizers.Adam()\n","discriminador_optimizer = tf.keras.optimizers.Adam()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IaOXZKxImUqh","colab":{}},"source":["#Para visualizar en cada etapa\n","\n","def generate_images(model, ts_input, tar, save_filename=False, display_imgs=True):\n","  \n","  prediction = model(ts_input, training=True)\n","\n","  if save_filename:\n","    tf.keras.preprocessing.image.save_img(PATH + 'output/' + save_filename + '.jpg', prediction[0,...])\n","    \n","  plt.figure(figsize=(16,6))\n","  \n","  plt.subplot(1, 3, 1)\n","  plt.title('Entrada')\n","  plt.imshow( ((ts_input[0])+1)/2 )\n","  plt.axis('off')\n","  \n","  plt.subplot(1, 3, 2)\n","  plt.title('Ground Truth')\n","  plt.imshow( ((tar[0])+1)/2 )\n","  plt.axis('off')\n","  \n","  plt.subplot(1, 3, 3)\n","  plt.title('Predición')\n","  plt.imshow( ((prediction[0])+1)/2 )\n","  plt.axis('off')\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1KnCw4JLFq0X","colab_type":"code","colab":{}},"source":["#Entrenamos el modelo\n","#Pasamos la imagen de entrada y la imagen esperada\n","@tf.function\n","def train_step(generar, discriminar, input_image, target):\n","  \n","  with tf.GradientTape() as gen_tape, tf.GradientTape() as discr_tape:\n","    \n","    #Imagen de salida a partir de la de entrada\n","    output_image = generar(input_image, training=True)\n","\n","    #Pasamos la imagen generada y la imagen de entrada\n","    output_pred_discr = discriminar([output_image, input_image], training=True)\n","\n","    #Imagen esperada y la imagen de entrada\n","    output_target_discr = discriminar([target, input_image], training=True)\n","\n","    #Recibimos la evaluación del discriminador\n","    discr_loss = discrimator_loss(output_target_discr, output_pred_discr)\n","    #Recibimos la evaluación del generador\n","    gen_loss = generator_loss(output_pred_discr,output_image, target)\n","\n","    #Calculamos el descenso del gradiente del generador\n","    generator_grads = gen_tape.gradient(gen_loss, generar.trainable_variables)\n","    #Calculamos el descenso del gradiente del discriminador\n","    discriminator_grads = discr_tape.gradient(discr_loss, discriminar.trainable_variables)\n","\n","    generador_optimizer.apply_gradients(zip(generator_grads, generar.trainable_variables))\n","    discriminador_optimizer.apply_gradients(zip(discriminator_grads, discriminar.trainable_variables))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KJDh9SrAEYOW","colab_type":"code","colab":{}},"source":["def train(generar, discriminar, train, test, epochs):\n","  for epoch in range(epochs):\n","\n","    imgi = 0\n","    for input_image, target in train:\n","      print ('epoch ' + str(epoch) + ' -> Entrenando -> ' + str(imgi) + '/' + str(len(tr_urls)))\n","      imgi = imgi + 1\n","      train_step(generar, discriminar, input_image, target)\n","      clear_output(wait=True) \n","    #rof \n","\n","    for inp, tar in test.take(5):\n","      generate_images(generar, inp, tar, #str(imgi) + '_' + \n","                      str(epoch), display_imgs=True)\n","    #rof\n","  #rof\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f4I41q8UzjK5","colab_type":"code","colab":{}},"source":["###Guardar avances\n","checkpoint_prefix = os.path.join(PATH + \"check\", \"ckpt\")\n","checkpoint = tf.train.Checkpoint(generator_optimizer=generador_optimizer,\n","                                discriminator_optimizer=discriminador_optimizer,\n","                                generator=G,\n","                                discriminator=D)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5YXY-TIMFSvT","colab_type":"code","colab":{}},"source":["#Cargamos el avance anterior\n","checkpoint.restore(tf.train.latest_checkpoint(PATH + \"check\"))\n","#Entrenamiento\n","train(G, D, X_train, X_test, 100)\n","#Guardamos el avance actual\n","checkpoint.save(file_prefix=checkpoint_prefix)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jODnURXJkQHq","colab_type":"code","colab":{}},"source":["#Cargamos SOLO el nombre de las imagenes en un listado\n","pred = !ls -1 \"{PREDPATH}\"\n","\n","now = datetime.now()\n","\n","#Guardamos el avance del día en forma de un lindo gif :3\n","filenames = sorted(pred)\n","imgs = []\n","for f in filenames:\n","    imgs.append(imageio.imread(PREDPATH + f))\n","imageio.mimsave(PATH + 'Gifs/' + str(now) + '.gif', imgs, duration=0.1, subrectangles=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kqhi2JpU71Zh","colab_type":"code","colab":{}},"source":["#####################################################################\n","#####Borra el check anterior y los outputs para ahorrar espacio######\n","#####################################################################"],"execution_count":null,"outputs":[]}]}